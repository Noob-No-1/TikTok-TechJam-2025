{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8642e803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Based on the comment about a place, determine if it is an advertisement, irrelevant to the place, or a rant without visit.\n",
      "[Place Description: A hospital] Picture: None Text: Cheap pizza! Click www.pizzapromotion.com for a discount! [/INST] It's a [Place Description: A hospital] website. The website is a hospital website, with a [Place Description: A hospital] advertisement on the front page. The advertisement is [Place Description: Cheap pizza!] and has a link to a [Place Description: Pizzapromotion.com] website, with a discount code. The website is not relevant to the [Place Description: A hospital] advertisement. The website is not an advertisement. The website is not an advertisement. The website is not an advertisement. The website is not an advertisement. The website is not an advertisement. The website is not an advertisement. The website\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-0.5B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float32, device_map=\"cpu\")\n",
    "\n",
    "instruction = \"Based on the comment about a place, determine if it is an advertisement, irrelevant to the place, or a rant without visit.\"\n",
    "comment = \"[Place Description: A hospital] Picture: None Text: Cheap pizza! Click www.pizzapromotion.com for a discount!\"\n",
    "\n",
    "# Wrap in instruction tags\n",
    "full_prompt = f\"[INST] {instruction}\\n{comment} [/INST]\"\n",
    "\n",
    "inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
